training {
  learningRate = 0.001
  batchSize = 32
  epochs = 10
}

model {
  lstmLayerSize = 64
}

spark {
  appName = "Spark LLM"
  master = "local[*]"
  jars = "s3://sparkllmbucket/jar/LLMDecoderSpark-assembly-0.1.0-SNAPSHOT.jar"
  hadoop {
    fs {
      defaultFS = "hdfs://localhost:9000"
    }
  }
  executor {
    memory = "4g"
  }
  local {
    dir = "hdfs://localhost:9000/spark/tmp"
  }
  eventLog {
    dir = "hdfs://localhost:9000/spark/events"
  }
  rdd {
    compress = "true"
  }
  io {
    compression {
      codec = "lz4"
    }
  }
}

hdfs {
  uri = "hdfs://localhost:9000/"
}

paths {
  model = "src/main/resources/trainedModel.zip"
  csv = "src/main/resources/training_metrics.csv"
}

data {
  windowSize = 64
  stride = 32
}

metrics {
  similarityThreshold = 0.05
}

trainingMaster{
   avgFreq=5
   workerPreFetchNumBatches=2
}
