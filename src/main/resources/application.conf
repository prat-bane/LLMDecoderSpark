training {
  learningRate = 0.001
  batchSize = 32
  epochs = 100
}

model {
  lstmLayerSize = 64
}

spark {
  appName = "Spark LLM"
  master = "yarn"
  jars = "s3://sparkllmbucket/jar/LLMDecoderSpark-assembly-0.1.0-SNAPSHOT.jar"
  hadoop {
    fs {
      defaultFS = "hdfs://ip-172-31-18-156.us-east-2.compute.internal:8020"
    }
  }
  executor {
    memory = "4g"
  }
  local {
    dir = "hdfs://ip-172-31-18-156.us-east-2.compute.internal:8020/spark/tmp"
  }
  eventLog {
    dir = "hdfs://ip-172-31-18-156.us-east-2.compute.internal:8020/spark/events"
  }
  rdd {
    compress = "true"
  }
  io {
    compression {
      codec = "lz4"
    }
  }
}

hdfs {
  uri = "hdfs://ip-172-31-18-156.us-east-2.compute.internal:8020/"
}

paths {
  model = "hdfs://ip-172-31-18-156.us-east-2.compute.internal:8020/input/spark/trainedModel.zip"
  csv = "hdfs://ip-172-31-18-156.us-east-2.compute.internal:8020/input/spark/training_metrics.csv"
}

data {
  windowSize = 128
  stride = 32
}
